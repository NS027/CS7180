{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Lerning with Python\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept\n",
    "\n",
    "### **Definition：** <br>\n",
    "  Ability to learn without being explicitly programmed （Using pattern)\n",
    "\n",
    "### **Major machine learning techniques:** <br>\n",
    "- Regression/Estimation\n",
    "  - Predicting continuous values\n",
    "- Classification\n",
    "  - Item class/category of case\n",
    "- Clustering\n",
    "  - Finding the structure of data; summarization\n",
    "- Association\n",
    "  - Frequent co-occurring items/events\n",
    "- Anomaly detection\n",
    "  - Discovering abnormal and unusual cases\n",
    "- Sequence mining\n",
    "  - Predicting next events; click stream\n",
    "- Dimension Reduction\n",
    "  - Reduce the size of data\n",
    "- REcommendation systems\n",
    "  - Recommending items\n",
    "\n",
    "### **Difference between AI and Machine Learning:**\n",
    "- AI\n",
    "  - Computer vision\n",
    "  - Language processing\n",
    "  - Creativity\n",
    "- Machine Learning\n",
    "  - Classification\n",
    "  - Clustering\n",
    "  - Neural Network\n",
    "- Revolution in ML:\n",
    "  - Deep learning\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python\n",
    "- NumPy\n",
    "- SciPy\n",
    "- matplotlib\n",
    "- pandas\n",
    "- scikit-learn [check the tutorial](https://www.youtube.com/watch?v=hDKCxebp88A)\n",
    "  - classification / regression / clustering algorithms\n",
    "  - data processing -> Train -> Algorithm setup -> Model fitting -> Prediction -> Evaluation --> Model export \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised vs Unsupervised\n",
    "- **Supervised**(controlled environment)\n",
    "  - Using label the data to teach model: *numerical* / *categorical*\n",
    "  - **classification** & **regression**\n",
    "- **Unsupervised**(Less controlled environment)\n",
    "  - Dimension reduction\n",
    "  - Density estimation\n",
    "  - Market basket analysis\n",
    "  - **Clustering**: group of data points or objects that are somehow similar\n",
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "\n",
    "### Regression\n",
    "- Variables\n",
    "  - Dependent variable: **X**\n",
    "  - Independent variable: **Y**\n",
    "\n",
    "- **Simple linear regression:**<br>\n",
    "  *residual error*: between actual and predict data, use *mean square error(MSE)* to define how big it is.\n",
    "- **Multiple linear variable:**<br>\n",
    "  *optimized parameters*\n",
    "  - ordinary least squares: takes time for large datasets\n",
    "  - optimization algorithm\n",
    "    - gradient descent\n",
    "    - proper approach\n",
    "\n",
    "### Model Regression\n",
    "- Dataset\n",
    "  - Train/Test\n",
    "- Training Accuracy\n",
    "  - Over-fit: capture and produce a non-generalized model\n",
    "- Out-of-Sample Accuracy\n",
    "  - Should have HIGH out-of-sample accuracy\n",
    "  - Using *train/test split* evaluation approach\n",
    "  - *K-fold cross validation* average accuracy\n",
    "- Evaluation Metrics\n",
    "  - **MAE** mean absolute error\n",
    "  - **MSE** mean square error\n",
    "  - **RMSE** root of mean square error\n",
    "  - **RAE** relative absolute error\n",
    "  - **RSE** relative square error\n",
    "    - $R^2$ $= 1 - RSE$\n",
    "\n",
    "### Non-Linear Regression\n",
    "- **Polynomial Regression**\n",
    "  - polynomial regression model can be transferred into linear regression model -> *Least Square*\n",
    "\n",
    "### Classification\n",
    "- Supervised learning approach\n",
    "- Binary(0,1) or multi-class classification\n",
    "- **Algorithm**\n",
    "  - Decision Trees (ID3, C4,5, C5.0)\n",
    "    1. choose an *attribute*\n",
    "    2. calculate the significance of attribute\n",
    "        - More *Predictiveness*, Less *Impurity*, Lower *Entropy*(randomness or uncertainty)\n",
    "        - Entropy -> *information gain* (increase the certainty), choose **HIGHER**\n",
    "    3. split data based on value\n",
    "    4. go back to step 1\n",
    "  - Naive Bayes\n",
    "  - Linear Discriminant Analysis\n",
    "  - k-Nearest Neighbor\n",
    "    1. pick up a k (by examine the *Accuracy*)\n",
    "    2. calculate the distance from all cases\n",
    "    3. find the nearest data point\n",
    "    4. choose the most popular value\n",
    "  - Logistic Regression\n",
    "    - binary data\n",
    "    - probabilistic results\n",
    "    - need linear decision boundary\n",
    "    - need to understand the impact of feature\n",
    "  - Neural Networks\n",
    "  - Support Vector Machines (SVM)\n",
    "    - Data *transformation*\n",
    "    - Kernelling(Integrated in the library):\n",
    "      - Linear\n",
    "      - Polynomial\n",
    "      - RBF\n",
    "      - Sigmoid\n",
    "    - find the *hyperplane* (choose *bigger* margin by *support vector*)\n",
    "    1. mapping data to *high-dimensional* feature space\n",
    "    2. find a *separator*\n",
    "- Evaluation Metrics\n",
    "  - Jaccard index\n",
    "  - F1-Score (Confusion matrix)(True Positive... TP/FN/FP/TN)\n",
    "    - $Precision = TP/(TP + FP)$\n",
    "    - $Recall = TP/(TP + FN)$\n",
    "    - $F1 = 2*(prc * rec)/(prc + rec)$\n",
    "  - Log loss\n",
    "\n",
    "\n",
    "### Clustering\n",
    "**Unlabeled dataset**\n",
    "A group of objects that *similar to other projects* and *dissimilar to data points* in other cluster.<br>\n",
    "#### Algorithm\n",
    "- Partitioned-based\n",
    "  - Relatively efficient\n",
    "  - k-Means, k-Median, Fuzzy c-Means\n",
    "- Hierarchical Clustering\n",
    "  - Produces trees of clusters\n",
    "  - Agglomerative, Divisive\n",
    "- Density-based\n",
    "  - Produces arbitrary shaped cluster\n",
    "  - DBSCAN\n",
    "#### K-Means\n",
    "- divides the data into *non-overlapping* subsets\n",
    "- Steps:\n",
    "  1. find k and their value -> *centroid* chosen randomly\n",
    "  2. calculate the distance between and make a matrix\n",
    "  3. assign each point to the closest centroid\n",
    "  4. the SSE(sum of the square errors) is high and compute new centroids for each cluster\n",
    "  5. repeat until there are no more changes\n",
    "- Accuracy\n",
    "  - external approach\n",
    "    - compare with ground truth (which is not possible for the most cases)\n",
    "  - internal approach\n",
    "    - average the distance between data points within a cluster\n",
    "  - with the increasing k, the accuracy is always decreasing. choose the **elbow point**\n",
    "#### Hierarchal \n",
    "*each node is a cluster* consists of the clusters of its daughter nodes\n",
    "- Agglomerative is going UP\n",
    "  - Steps:\n",
    "    1. create *n* clusters\n",
    "    2. computer the proximity matrix\n",
    "    3. Repeat\n",
    "       - Merge the two closest clusters\n",
    "       - Update the matrix \n",
    "    4. Until only single cluster remains \n",
    "- Divisive is going DOWN \n",
    "#### DBSCAN\n",
    "locates regions of *high density* and separates outliers, for class identification\n",
    "Density-Based Spatial Clustering of Applications with Noise <br>\n",
    "- R (Radius of neighborhood)\n",
    "- M (Min number of neighbors)\n",
    "- each point is either:\n",
    "  - core\n",
    "  - border\n",
    "    - less than the M\n",
    "    - reachable from the core point\n",
    "  - outlier\n",
    "    - not reachable from the core point\n",
    "- if the core point can be reached with the R, all of these core points should connect together into ONE cluster\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
